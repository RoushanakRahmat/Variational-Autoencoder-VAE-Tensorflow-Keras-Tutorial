A simple python tutorial of VAEs in keras/tensorflow training on the Fashion MNIST dataset

A variational autoencoder (VAE) is a type of generative models which is rooted in probabilistic graphical models and variational Bayesian methods, introduced by Diederik P. Kingma and Max Welling that learns to reproduce its input, and also map data to latent space.
VAE provides a probabilistic manner to describe an observation in latent space with a probability distribution (μ, σ) which instead of just building an encoder that outputs a single value to describe each latent state attribute, the encoder in VAE is formulated to describe a probability distribution for each latent attribute.

More details about this tutorial can be found on https://medium.com/@roushanakrahmat/variational-autoencoder-vae-tensorflow-keras-tutorial-e96d8fa87664
